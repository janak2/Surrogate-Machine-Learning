{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4132,"status":"ok","timestamp":1666623419386,"user":{"displayName":"Janak Agrawal","userId":"14377288670060290274"},"user_tz":-330},"id":"W0uWtyfxQBzw"},"outputs":[],"source":["import torch\n","import torch.utils.data as data_utils\n","from torch.nn import Module\n","from torch.nn import Conv2d, Conv1d\n","from torch.nn import Linear\n","from torch.nn import MaxPool2d, MaxPool1d\n","from torch.nn import ReLU\n","from torch.nn import LogSoftmax\n","from torch import flatten, tensor\n","import pandas as pd\n","import numpy as np\n","from torch.optim import Adam\n","import time\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":14040,"status":"ok","timestamp":1666623433424,"user":{"displayName":"Janak Agrawal","userId":"14377288670060290274"},"user_tz":-330},"id":"o8NlTKvZQa-M"},"outputs":[],"source":["df_input = pd.read_csv('input.csv', index_col=0)\n","df_output = pd.read_csv('output.csv', index_col=0)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1666623433424,"user":{"displayName":"Janak Agrawal","userId":"14377288670060290274"},"user_tz":-330},"id":"IVU7cVPfmqWd"},"outputs":[],"source":["# define training hyperparameters\n","INIT_LR = 1e-3\n","BATCH_SIZE = 64\n","EPOCHS = 10\n","# define the train and val splits\n","TRAIN_SPLIT = 0.75\n","VAL_SPLIT = 1 - TRAIN_SPLIT\n","# set the device we will be using to train the model\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":833,"status":"ok","timestamp":1666623434248,"user":{"displayName":"Janak Agrawal","userId":"14377288670060290274"},"user_tz":-330},"id":"cYpHKytyapwD"},"outputs":[],"source":["def create_test_train_data(df_input, df_output):\n","  train_x = df_input.sample(frac=0.8)\n","  train_y = df_output.loc[train_x.index]\n","\n","  test_x = df_input.drop(train_x.index)\n","  test_y = df_output.loc[test_x.index]\n","\n","  return train_x, train_y, test_x, test_y"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1666623434249,"user":{"displayName":"Janak Agrawal","userId":"14377288670060290274"},"user_tz":-330},"id":"Zk3YOFBic-sk"},"outputs":[],"source":["train_x, train_y, test_x, test_y = create_test_train_data(df_input, df_output)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1666623434249,"user":{"displayName":"Janak Agrawal","userId":"14377288670060290274"},"user_tz":-330},"id":"xcnVr03Ile9_"},"outputs":[],"source":["train_target = tensor(train_y.iloc[:,-1].values)\n","train = tensor(train_x.values) \n","train_tensor = data_utils.TensorDataset(train, train_target) \n","train_loader = data_utils.DataLoader(dataset = train_tensor, batch_size = BATCH_SIZE, shuffle = True)\n","\n","test_target = tensor(test_y.iloc[:,-1].values)\n","test = tensor(test_x.values) \n","test_tensor = data_utils.TensorDataset(test, test_target) \n","test_loader = data_utils.DataLoader(dataset = test_tensor, batch_size = BATCH_SIZE, shuffle = True)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1666623434249,"user":{"displayName":"Janak Agrawal","userId":"14377288670060290274"},"user_tz":-330},"id":"f0nT5KQsdJcL"},"outputs":[],"source":["class LeNet(Module):\n","\n","\tdef __init__(self):\n","\t\t# call the parent constructor\n","\t\tsuper(LeNet, self).__init__()\n","\t\t# initialize first set of CONV => RELU => POOL layers\n","\t\tself.conv1 = Conv1d(in_channels=1, out_channels=1, kernel_size=5)\n","\t\tself.relu1 = ReLU()\n","\t\tself.maxpool1 = MaxPool1d(kernel_size=2, stride= 2)\n","\t\t# initialize second set of CONV => RELU => POOL layers\n","\t\tself.conv2 = Conv1d(in_channels=20, out_channels=50, kernel_size=5)\n","\t\tself.relu2 = ReLU()\n","\t\tself.maxpool2 = MaxPool1d(kernel_size=2, stride= 2)\n","\t\t# initialize first (and only) set of FC => RELU layers\n","\t\tself.fc1 = Linear(in_features=800, out_features=500)\n","\t\tself.relu3 = ReLU()\n","\t\t# initialize our softmax classifier\n","\t\tself.fc2 = Linear(in_features=500, out_features=1)\n","\t\tself.logSoftmax = LogSoftmax(dim=1)\n","    \n","\tdef forward(self, x):\n","\t\t# pass the input through our first set of CONV => RELU =>\n","\t\t# POOL layers\n","\t\tx = self.conv1(x)\n","\t\tx = self.relu1(x)\n","\t\tx = self.maxpool1(x)\n","\t\t# pass the output from the previous layer through the second\n","\t\t# set of CONV => RELU => POOL layers\n","\t\tx = self.conv2(x)\n","\t\tx = self.relu2(x)\n","\t\tx = self.maxpool2(x)\n","\t\t# flatten the output from the previous layer and pass it\n","\t\t# through our only set of FC => RELU layers\n","\t\tx = flatten(x, 1)\n","\t\tx = self.fc1(x)\n","\t\tx = self.relu3(x)\n","\t\t# pass the output to our softmax classifier to get our output\n","\t\t# predictions\n","\t\tx = self.fc2(x)\n","\t\toutput = self.logSoftmax(x)\n","\t\t# return the output predictions\n","\t\treturn output"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1666623434250,"user":{"displayName":"Janak Agrawal","userId":"14377288670060290274"},"user_tz":-330},"id":"HHOmV0zXk4VF"},"outputs":[],"source":["trainSteps = len(train_loader.dataset) // BATCH_SIZE\n","valSteps = len(test_loader.dataset) // BATCH_SIZE"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1666623434250,"user":{"displayName":"Janak Agrawal","userId":"14377288670060290274"},"user_tz":-330},"id":"4diLxrz4n4I3","outputId":"061780ba-28ed-4d40-9d1a-1f8ce6e77ec4"},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO] initializing the LeNet model...\n","[INFO] training the network...\n"]}],"source":["print(\"[INFO] initializing the LeNet model...\")\n","model = LeNet().to(device)\n","# initialize our optimizer and loss function\n","opt = Adam(model.parameters(), lr=INIT_LR)\n","lossFn = torch.nn.NLLLoss()\n","# initialize a dictionary to store training history\n","H = {\n","\t\"train_loss\": [],\n","\t\"train_acc\": [],\n","\t\"val_loss\": [],\n","\t\"val_acc\": []\n","}\n","# measure how long training is going to take\n","print(\"[INFO] training the network...\")\n","startTime = time.time()"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"executionInfo":{"elapsed":5,"status":"error","timestamp":1666623434250,"user":{"displayName":"Janak Agrawal","userId":"14377288670060290274"},"user_tz":-330},"id":"20pMI8UcoYr_","outputId":"53b8dc51-1837-4c35-8747-b480c4ed9ae5"},"outputs":[{"ename":"RuntimeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-38ad11d30245>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0;31m# perform a forward pass and calculate the training loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossFn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0;31m# zero out the gradients, perform the backpropagation step,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-426f16f02fba>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0;31m# pass the input through our first set of CONV => RELU =>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0;31m# POOL layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    302\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m    303\u001b[0m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0;32m--> 304\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [1, 1, 5], expected input[1, 64, 1200] to have 1 channels, but got 64 channels instead"]}],"source":["for e in range(0, EPOCHS):\n","\t# set the model in training mode\n","\tmodel.train()\n","\t# initialize the total training and validation loss\n","\ttotalTrainLoss = 0\n","\ttotalValLoss = 0\n","\t# initialize the number of correct predictions in the training\n","\t# and validation step\n","\ttrainCorrect = 0\n","\tvalCorrect = 0\n","\t# loop over the training set\n","\tfor (x, y) in train_loader:\n","\t\t# send the input to the device\n","\t\t(x, y) = (x.to(device), y.to(device))\n","\t\t# perform a forward pass and calculate the training loss\n","\t\tpred = model(x)\n","\t\tloss = lossFn(pred, y)\n","\t\t# zero out the gradients, perform the backpropagation step,\n","\t\t# and update the weights\n","\t\topt.zero_grad()\n","\t\tloss.backward()\n","\t\topt.step()\n","\t\t# add the loss to the total training loss so far and\n","\t\t# calculate the number of correct predictions\n","\t\ttotalTrainLoss += loss\n","\t\ttrainCorrect += (abs(pred-y)/len(y)).type(\n","\t\t\ttorch.float).sum().item()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1666623434250,"user":{"displayName":"Janak Agrawal","userId":"14377288670060290274"},"user_tz":-330},"id":"C_jB_9rufg3N"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOBaziZ0mFVPSssaL8perkL","collapsed_sections":[],"mount_file_id":"1GBDJOVZbx2GnQ_a5pTTSak6nn2G9r9iZ","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
